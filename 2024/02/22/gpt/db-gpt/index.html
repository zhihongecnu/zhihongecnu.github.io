<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>DB-GPT | 实践指南 | 学习空间</title><meta name="keywords" content="GPT"><meta name="author" content="Rex"><meta name="copyright" content="Rex"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="DB-GPT 实践指南及魔改方法">
<meta property="og:type" content="article">
<meta property="og:title" content="DB-GPT | 实践指南">
<meta property="og:url" content="http://www.wzhecnu.cn/2024/02/22/gpt/db-gpt/index.html">
<meta property="og:site_name" content="学习空间">
<meta property="og:description" content="DB-GPT 实践指南及魔改方法">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qiniu.wzhecnu.cn/PicBed6/picgo/20240305154701.png">
<meta property="article:published_time" content="2024-02-21T18:48:48.000Z">
<meta property="article:modified_time" content="2024-03-24T03:19:21.688Z">
<meta property="article:author" content="Rex">
<meta property="article:tag" content="GPT">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qiniu.wzhecnu.cn/PicBed6/picgo/20240305154701.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://www.wzhecnu.cn/2024/02/22/gpt/db-gpt/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="/css/iconfont.css"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":300},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'DB-GPT | 实践指南',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-24 11:19:21'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><script>(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();</script><link rel="stylesheet" href="APlayer.min.css"><div id="aplayer"></div><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js" async></script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://qiniu.wzhecnu.cn/PicBed5/images_for_blogs/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">95</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">28</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://qiniu.wzhecnu.cn/PicBed6/picgo/20240305154701.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">学习空间</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">DB-GPT | 实践指南</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发布于</span><time class="post-meta-date-created" datetime="2024-02-21T18:48:48.000Z" title="发布于 2024-02-22 02:48:48">2024-02-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-03-24T03:19:21.688Z" title="更新于 2024-03-24 11:19:21">2024-03-24</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>11分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="唠唠闲话">唠唠闲话</h2>
<p>DB-GPT 是一个开源的 AI 原生数据应用开发框架 AI Native Data App Development framework with AWEL and Agents。该项目旨在构建大模型领域的基础设施，通过开发：</p>
<ul>
<li>多模型管理(SMMF, Service-oriented Multi-model Management Framework)</li>
<li>Text2SQL 效果优化</li>
<li>RAG 框架以及优化</li>
<li>Multi-Agents 框架协作</li>
<li>AWEL(智能体工作流编排)</li>
</ul>
<p>等多种技术能力，让围绕数据库构建大模型应用更简单，更方便。数据 3.0 时代，基于模型、数据库，企业/开发者可以用更少的代码搭建自己的专属应用。</p>
<p>当前发展趋势的变化：</p>
<ul>
<li>服务类型的变化：IaaS/PaaS/SaaS =&gt; AaaS</li>
<li>开发模式的变化：DevOps =&gt; LLMOps</li>
</ul>
<p>DB-GPT 官方文档：</p>
<ul>
<li>中文文档（语雀）：<a target="_blank" rel="noopener" href="https://www.yuque.com/eosphoros/dbgpt-docs/">https://www.yuque.com/eosphoros/dbgpt-docs/</a></li>
<li>英文文档：<a target="_blank" rel="noopener" href="https://docs.dbgpt.site/docs/overview">https://docs.dbgpt.site/docs/overview</a></li>
</ul>
<p>注：中文文档更新不全，且存在错误，建议以英文文档为准。</p>
<h3 id="项目特性">项目特性</h3>
<p>项目示意图：<br>
<img src="https://cdn.nlark.com/yuque/0/2023/png/23108892/1701074256243-910a0df1-ff67-4a59-abbd-b4ac87cad1f2.png?x-oss-process=image%2Fresize%2Cw_1500%2Climit_0" alt="项目示意图"></p>
<table>
<thead>
<tr>
<th>名词</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>DB-GPT</td>
<td>一个开源的 AI 原生数据应用开发框架</td>
</tr>
<tr>
<td>AWEL</td>
<td>Agentic Workflow Expression Language,  智能体工作流表达式语言</td>
</tr>
<tr>
<td>AWEL Flow</td>
<td>使用智能体工作流语言编排的工作流</td>
</tr>
<tr>
<td>LLMOps</td>
<td>大语言模型操作框架，提供标准的端到端工作流程，用于训练、调整、部署和监控 LLM，以加速生成 AI 模型的应用程序部署</td>
</tr>
<tr>
<td>Plugin</td>
<td>插件, 主要用来完成某一个或者某一类具体的动作。</td>
</tr>
<tr>
<td>Datasource</td>
<td>数据源，比如 MySQL、PG、StarRocks、Clickhouse 等。</td>
</tr>
<tr>
<td>Text2SQL/NL2SQL</td>
<td>Text to SQL，利用大语言模型能力，根据自然语言生成 SQL 语句，或者根据 SQL 语句给出解释说明</td>
</tr>
<tr>
<td>KBQA</td>
<td>Knowledge-Based Q&amp;A  基于知识库的问答系统</td>
</tr>
<tr>
<td>GBI</td>
<td>Generative Business Intelligence 生成式商业智能，基于大模型与数据分析，通过对话方式提供商业智能分析与决策</td>
</tr>
<tr>
<td>Embedding</td>
<td>将文本、音频、视频等资料转换为向量的方法</td>
</tr>
<tr>
<td>RAG</td>
<td>Retrieval-Augmented Generation 检索能力增强</td>
</tr>
</tbody>
</table>
<h3 id="博客定位">博客定位</h3>
<p>博客将从实践角度，围绕以下几个要点介绍 DB-GPT 的特性：</p>
<!-- 1. 怎么管理模型，包括部署本地模型，部署 API 模型，以及模型推理 -->
<ol start="2">
<li>支持的知识库有哪些，怎么添加，以及怎么使用</li>
<li>智能体的构建方式，以及如何使用 AWEL Flow</li>
<li>前端的可视化，以及与用户的交互方式</li>
</ol>
<p>实践的 DB-GPT 版本为 0.5.0，这个版本开始为 DB-GPT 第一个长期维护的版本。</p>
<!-- 
1. 模型的部署指南，多模型管理控制 | BIChat 
2. 知识库构建及使用指南 | 
3. 对话应用的构建
4. AWEL 的使用指南
5. 前端页面魔改指南

实践的 DB-GPT 版本为 0.4.4。 -->
<h2 id="服务部署">服务部署</h2>
<p>DB-GPT 提供了。这部分本身也可以单独作为一个工具使用。</p>
<h3 id="0-安装环境">0. 安装环境</h3>
<p>通过源码安装，其中 Python 版本建议小于 3.10</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/eosphoros-ai/DB-GPT.git</span><br><span class="line"><span class="built_in">cd</span> DB-GPT</span><br><span class="line">conda create -n dbgpt_env <span class="string">&quot;python=3.10&quot;</span></span><br><span class="line">conda activate dbgpt_env</span><br><span class="line"><span class="comment"># 等待安装完成</span></span><br><span class="line"><span class="comment"># pip install transformers==4.35.0</span></span><br><span class="line">pip install -e <span class="string">&quot;.[openai]&quot;</span></span><br><span class="line">pip install -e <span class="string">&quot;.[default]&quot;</span></span><br><span class="line">pip install cryptography <span class="comment"># 连接 MySQL 数据库需要</span></span><br><span class="line"><span class="comment"># pip install -U langchain-community</span></span><br><span class="line"><span class="comment"># pip install -e &quot;.[vllm]&quot;</span></span><br></pre></td></tr></table></figure>
<p>如果遇到环境依赖问题，再根据报错信息灵活处理。</p>
<h3 id="1-模型管理">1. 模型管理</h3>
<p>启动模型控制器：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dbgpt start controller <span class="comment"># 默认端口 8000 --port 修改</span></span><br></pre></td></tr></table></figure>
<p>以下假设服务在 <code>172.23.148.37</code> 下启动，其他模型则通过局域网的其他服务器启动。</p>
<h4 id="添加本地模型">添加本地模型</h4>
<p>启动本地模型，比如 chatglm3-6b：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CUDA_VISIBLE_DEVICES=0,1</span></span><br><span class="line">dbgpt start worker --model_name chatglm3-6b \</span><br><span class="line">    --model_path /sshfs/pretrains/THUDM/chatglm3-6b \</span><br><span class="line">    --port 8001 \</span><br><span class="line">    --load_4bit \</span><br><span class="line">    --num_gpus 2 \</span><br><span class="line">    --controller_addr http://172.23.148.37:8000</span><br></pre></td></tr></table></figure>
<p>其中 <code>--controller_addr</code> 填写控制器所在的服务器地址，如果是本地则填写 <code>127.0.0.1</code>。</p>
<p>回到控制器服务器，查看模型列表：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">❯ dbgpt model list</span><br><span class="line">+---------------+------------+---------------+------+---------+---------+-----------------+----------------------------+</span><br><span class="line">|   Model Name  | Model Type |      Host     | Port | Healthy | Enabled | Prompt Template |       Last Heartbeat       |</span><br><span class="line">+---------------+------------+---------------+------+---------+---------+-----------------+----------------------------+</span><br><span class="line">|  chatglm3-6b  |    llm     | 172.23.148.35 | 8001 |   True  |   True  |                 | 2024-03-04T23:37:01.359224 |</span><br><span class="line">| WorkerManager |  service   | 172.23.148.35 | 8001 |   True  |   True  |                 | 2024-03-04T23:37:01.414130 |</span><br><span class="line">+---------------+------------+---------------+------+---------+---------+-----------------+----------------------------+</span><br></pre></td></tr></table></figure>
<p>测试模型：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">❯ dbgpt model chat --model_name chatglm3-6b</span><br><span class="line">Chatbot started with model chatglm3-6b. Type <span class="string">&#x27;exit&#x27;</span> to leave the chat.</span><br><span class="line">You: hello</span><br><span class="line">Bot: Hello 👋! I<span class="string">&#x27;m ChatGLM3-6B, the artificial intelligence assistant, nice to meet you. Feel free to ask me any questions.</span></span><br></pre></td></tr></table></figure>
<p>注意事项：</p>
<ol>
<li>一个端口只能注册一个模型，注册后，该端口会启动一个 WorkerManager 服务</li>
<li>模型关闭后，<code>dbgpt model list</code> 仍会显示注册过但已关闭的模型，其 <code>Healthy</code> 为 <code>False</code>。同样地，网页端也仍会显示<br>
<img src="https://qiniu.wzhecnu.cn/PicBed6/picgo/20240305021511.png" alt="20240305021511"></li>
<li>Worker 默认会使用所有可用的 GPU，且 <code>--num_gpus</code> 参数似乎没用，还是得用 <code>CUDA_VISIBLE_DEVICES</code> 控制。</li>
<li>如果指定了 <code>worker_type</code>，则参数规则会改变，比如 <code>vllm</code> 是用 <code>--tensor_parallel_size</code> 参数指定 tensor 并行的数量，用 <code>--num_gpus</code> 参数会报错。</li>
</ol>
<h4 id="添加嵌入模型">添加嵌入模型</h4>
<p>添加 Embedding 模型：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dbgpt start worker --model_name text2vec-large-chinese \</span><br><span class="line">    --model_path /sshfs/pretrains/GanymedeNil/text2vec-large-chinese \</span><br><span class="line">    --worker_type text2vec \</span><br><span class="line">    --port 8002 \</span><br><span class="line">    --controller_addr http://172.23.148.37:8000</span><br></pre></td></tr></table></figure>
<p>这里 <code>worker_type</code> 设置为 <code>text2vec</code>。</p>
<h4 id="vLLM-加载模型">vLLM 加载模型</h4>
<p>这部分需要安装 vllm 模块，使用 <code>pip install -e &quot;.[vllm]&quot;</code> 安装。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dbgpt start worker --model_name chatglm3-6b \</span><br><span class="line">    --model_path /sshfs/pretrains/THUDM/chatglm3-6b \</span><br><span class="line">    --port 8001 \</span><br><span class="line">    --model_type vllm \</span><br><span class="line">    --tensor_parallel_size 2\</span><br><span class="line">    --controller_addr http://localhost:8011</span><br></pre></td></tr></table></figure>
<p>似乎没有正常启动，尽管推理时显存有占用，但回答结果空白，可能需要设置停止词之类的。</p>
<h4 id="添加-API-模型">添加 API 模型</h4>
<p>文档这部分写得一言难尽，这些参数的规则需要结合 <code>.env</code> 文件和网页端推理出来。</p>
<p>添加 OpenAI 模型：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dbgpt start worker --model_name chatgpt \</span><br><span class="line">    --model_path chatgpt_proxyllm \</span><br><span class="line">    --worker_type llm \</span><br><span class="line">    --port 8003 \</span><br><span class="line">    --proxy_server_url https://api.chatanywhere.tech/v1/chat/completions \</span><br><span class="line">    --proxy_api_key <span class="variable">$OPENAI_API_KEY</span> \</span><br><span class="line">    --controller_addr http://172.23.148.37:8000</span><br></pre></td></tr></table></figure>
<p>添加智谱模型：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dbgpt start worker --model_name zhipu_proxyllm \</span><br><span class="line">    --model_path zhipu_proxyllm \</span><br><span class="line">    --worker_type llm \</span><br><span class="line">    --port 8004 \</span><br><span class="line">    --proxy_server_url https://open.bigmodel.cn/api/paas/v4/chat/completions \</span><br><span class="line">    --proxy_api_key <span class="variable">$ZHIPU_API_KEY</span> \</span><br><span class="line">    --proxyllm_backend glm-4 \</span><br><span class="line">    --controller_addr http://172.23.148.37:8000</span><br></pre></td></tr></table></figure>
<p>添加 OpenAI Embedding 模型：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dbgpt start worker --model_name openai-embedding \</span><br><span class="line">    --model_path chatgpt_proxyllm \</span><br><span class="line">    --worker_type llm \</span><br><span class="line">    --port 8005 \</span><br><span class="line">    --proxy_server_url https://api.chatanywhere.tech/v1/embeddings \</span><br><span class="line">    --proxy_api_key <span class="variable">$OPENAI_API_KEY</span> \</span><br><span class="line">    --proxyllm_backend text-embedding-ada-002\</span><br><span class="line">    --controller_addr http://172.23.148.37:8000</span><br></pre></td></tr></table></figure>
<p>谷歌，微软等模型的添加方式类似。</p>
<blockquote>
<p>实测环境变量也有影响。</p>
</blockquote>
<h4 id="模型推理">模型推理</h4>
<p>模型能以兼容 OpenAI 的方式推理，具体地，先启动 API Server 服务：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dbgpt start apiserver --api_keys EMPTY --controller_addr http://127.0.0.1:8000 <span class="comment"># 默认值，可以不填</span></span><br></pre></td></tr></table></figure>
<p>参数说明：</p>
<ul>
<li><code>--api_keys</code>：API 的 key，如果有多个，用逗号分隔；如果不填写，则允许所有密钥；这里将密钥设置为 <code>EMPTY</code> 这个单词。</li>
<li><code>--controller_addr</code>：控制器地址，可不填，与上边等同。</li>
<li><code>--port</code>：端口号，默认 8100。</li>
<li><code>--host</code>：监听的地址，默认 <code>0.0.0.0</code>。</li>
</ul>
<p>测试模型：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl http://127.0.0.1:8100/api/v1/chat/completions \</span><br><span class="line">    -H <span class="string">&quot;Authorization: Bearer EMPTY&quot;</span> \</span><br><span class="line">    -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">    -d <span class="string">&#x27;&#123;&quot;model&quot;: &quot;chatglm3-6b&quot;, &quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;hello&quot;&#125;]&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>吐槽一下：官方的中文文档，这部分把端口的规则写反了。。。</p>
</blockquote>
<h3 id="2-启动服务">2. 启动服务</h3>
<h4 id="加载-Embedding-模型">加载 Embedding 模型</h4>
<p>需要下载 Embedding 模型才能正常启动，尽管启动选项提供了 <code>--remote_embedding</code> 来使用 Worker 中的模型，但实际运行会报错，待处理。</p>
<p>下载模型到仓库目录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd DB-GPT</span></span><br><span class="line"><span class="built_in">mkdir</span> models &amp;&amp; <span class="built_in">cd</span> models</span><br><span class="line"><span class="comment"># download embedding model, eg: text2vec-large-chinese</span></span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/GanymedeNil/text2vec-large-chinese</span><br></pre></td></tr></table></figure>
<h4 id="配置环境变量">配置环境变量</h4>
<p>复制环境变量文件并修改</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> .env.template .<span class="built_in">env</span></span><br></pre></td></tr></table></figure>
<p>一个简单的配置例子，可以直接粘贴，或者修改对应选项：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># .env</span></span><br><span class="line">LANGUAGE=zh <span class="comment"># 语言</span></span><br><span class="line">LLM_MODEL=zhipu_proxyllm <span class="comment"># 模型名称</span></span><br><span class="line">MODEL_SERVER=http://127.0.0.1:8000 <span class="comment"># 控制器地址</span></span><br><span class="line">ZHIPU_MODEL_VERSION=glm-4</span><br><span class="line">ZHIPU_PROXY_API_KEY=&#123;your_api_key&#125;</span><br></pre></td></tr></table></figure>
<p>启动服务：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dbgpt start webserver --light <span class="comment"># 默认端口 5000</span></span><br></pre></td></tr></table></figure>
<p>由于使用多模型管理，这里必须用 <code>--light</code> 参数，将模型加载交给控制器，而不是使用 <code>.env</code> 的模型配置。其中变量 <code>LLM_MODEL</code> 将用作默认模型，请确保模型列表中有该模型。</p>
<p>这里还有些参数，后续有需要再补充。</p>
<blockquote>
<p>变量的读取规则尚不清楚，应该是：环境变量 &gt; <code>.env</code> 文件 &gt; 默认值。待确认。</p>
</blockquote>
<h4 id="服务介绍">服务介绍</h4>
<p>通过 <code>服务器IP:5000</code> 访问服务，如下图所示，启动了四个模型：</p>
<p><img src="https://qiniu.wzhecnu.cn/PicBed6/picgo/20240305025702.png" alt="20240305025702"></p>
<p>左侧为对话列表，下方包括五个模块：</p>
<ol>
<li>APP 应用</li>
<li>AWEL Flow 智能体工作流</li>
<li>Models 模型管理</li>
<li>Database 数据库</li>
<li>Knowledge 知识库</li>
</ol>
<p>从 0.5.0 版本开始，DB-GPT 项目原生集成了 data-centric 程序的管理和分发。dbgpts 项目管理和分享的资源分为以下几类：</p>
<ul>
<li>应用程序：使用 DB-GPT 框架开发的原生智能数据应用程序。</li>
<li>工作流：使用 AWEL（Agentic Workflow Expression Language）构建的工作流程。</li>
<li>智能代理：可以执行各种任务的智能代理。</li>
<li>操作算子：可以在工作流程中使用的基本操作单位。</li>
</ul>
<p>以上主要介绍了服务部署和模型管理。下边我们将在实战过程中，介绍这些板块的用法。</p>
<h2 id="知识问答">知识问答</h2>
<p>第一部分，针对文件知识库的 RAG 问答，针对结构化知识库的工具问答。</p>
<h3 id="知识库问答">知识库问答</h3>
<p>Q：支持的知识库有哪些，怎么添加，以及怎么使用。</p>
<ol>
<li>
<p>支持：纯文本、URL抓取、PDF、Word、Markdown 等多种文档类型</p>
</li>
<li>
<p>创建对话：选择知识库对话，结合知识库的文档进行问答。初始 Prompt 可以在知识库中修改，聊天会自动使用 RAG 抽取信息，拼接到 Prompt 中。</p>
</li>
<li>
<p>在知识库对话下，允许用户直接上传文件进行对话，且默认会触发文档的总结能力。上传的文件也会传入该知识库。</p>
</li>
</ol>
<hr>
<ol start="4">
<li>
<p>潜在问题：.py 等文件直接导入会显示 TODO。直接上传也一样</p>
</li>
<li>
<p>大文件导入比较久，RUNNING 默认用了 CPU 推理，怎么修改。</p>
</li>
<li>
<p>空白对话也有默认 Prompt，暂时不知道怎么改。</p>
</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PROMPT_SCENE_DEFINE_EN = <span class="string">&quot;You are a helpful AI assistant.&quot;</span></span><br><span class="line">PROMPT_SCENE_DEFINE_ZH = <span class="string">&quot;你是一个有用的 AI 助手。&quot;</span></span><br></pre></td></tr></table></figure>
<p>总结：能够按知识库进行归类，进行问答。待修缮：文件导入，Prompt 修改，GPU 设置。</p>
<p>注：从模型调用结果来看，其结合了 RAG 检索知识库和模板拼接。</p>
<h3 id="数据问答">数据问答</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install cryptography</span><br></pre></td></tr></table></figure>
<p>添加数据后，在 ChatData 板块进行问答。会根据用户问题，生成代码，进行回答。</p>
<p>亲测除了 chatglm3-6b，基本都能完成。界面的 Editor 支持对代码记性修改。</p>
<p>Q：生成过程是怎么进行的？</p>
<p>A：从日志可以看出，基于形如下边的 Prompt</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">请根据用户选择的数据库和该库的部分可用表结构定义来回答用户问题.</span><br><span class="line">数据库名:</span><br><span class="line">case_1_student_manager 表结构定:[<span class="string">&#x27;&#x27;</span>]</span><br><span class="line">约束</span><br><span class="line">1. 请根据用户问题理解用户意图，使用给出表结构定义创建一个语法正确的 mysql sql，如果不需要sql，则直接回答用户问题。</span><br><span class="line">2. 除非用户在问题中指定了他希望获得的具体数据行数，否则始终将查询限制为最多 50 个结果。</span><br><span class="line">3. 只能使用表结构信息中提供的表来生成 sql，如果无法根据提供的表结构中生成 sql ，请说：“提供的表结构信息不足以生成 sql 查询。” 禁止随意捏造信</span><br><span class="line">...</span><br><span class="line">用户问题:</span><br><span class="line">    查询前十个学生的信息</span><br><span class="line">请一步步思考并按照以下JSON格式回复：                                                                                                                                                <span class="string">&quot;&#123;\n    \&quot;thoughts\&quot;: \&quot;thoughts summary to say to user\&quot;,\n    \&quot;sql\&quot;: \&quot;SQL Query to run\&quot;,\n    \&quot;display_type\&quot;: \&quot;Data display method\&quot;\n&#125;&quot;</span></span><br><span class="line">确保返回正确的json并且可以被 Python json.loads 方法解析.</span><br></pre></td></tr></table></figure>
<p>思考过程：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&quot;thoughts&quot;</span>: <span class="string">&quot;为了查询前十个学生的信息，我们可以使用 `SELECT` 语句从 `students` 表中选择 `student_id` 和 `student_name` 列，并按照 `student_id` 升序排列。&quot;</span>, <span class="string">&quot;sql&quot;</span>: <span class="string">&quot;SELECT student_id, student_name FROM students ORDER BY student_id LIMIT 10&quot;</span>,<span class="string">&quot;display_type&quot;</span>: <span class="string">&quot;Data display method&quot;</span></span><br></pre></td></tr></table></figure>
<p>系统背后：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">editor_sql_run:&#123;<span class="string">&#x27;db_name&#x27;</span>: <span class="string">&#x27;case_1_student_manager&#x27;</span>, <span class="string">&#x27;sql&#x27;</span>: <span class="string">&#x27;SELECT student_id, student_name FROM students ORDER BY student_id LIMIT 10&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>Q1：ChatDB 做什么用的，似乎只能看到结构，不能执行动作。</p>
<p>Q2: ChatExcel 似乎当成数据库来操作了</p>
<p>Q3: ChatDashboard 支持分析需要的功能，但当前的前端页面容易丢失信息。</p>
<hr>
<p>还有个问题，所有对话，不支持修改历史记录，或者重新生成这一类操作。</p>
<h2 id="开发设计">开发设计</h2>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install Poetry</span><br></pre></td></tr></table></figure>
<p>目前支持三个内容：</p>
<ol>
<li>插件开发，比如调用百度搜索</li>
<li>AWEL 流</li>
<li>应用构建</li>
</ol>
<p>BIChat：</p>
<p>直接启动，推理停止词</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># BIChat</span></span><br><span class="line">pip install einops transformers_stream_generator</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dbgpt start worker --model_name bichat \</span><br><span class="line">    --model_path chatgpt_proxyllm \</span><br><span class="line">    --worker_type llm \</span><br><span class="line">    --port 8008 \</span><br><span class="line">    --proxy_server_url http://172.23.148.39:8111/v1/chat/completions \</span><br><span class="line">    --proxy_api_key sk-123 \</span><br><span class="line">    --stop <span class="string">&quot;&lt;|endoftext|&gt;&quot;</span>\</span><br><span class="line">    --proxyllm_backend bichat --controller_addr http://localhost:8000</span><br></pre></td></tr></table></figure>
<p>API 启动</p>
<p>示例：</p>
<h2 id="前端页面魔改">前端页面魔改</h2>
<p>npm install @emotion/react @emotion/styled</p>
<p>npm config get registry</p>
<p>npm config set registry <a target="_blank" rel="noopener" href="https://r.cnpmjs.org">https://r.cnpmjs.org</a><br>
npm install @mui/material @mui/icons-material</p>
<hr>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Rex</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://www.wzhecnu.cn/2024/02/22/gpt/db-gpt/">http://www.wzhecnu.cn/2024/02/22/gpt/db-gpt/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">文章采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank">CC BY-NC-SA 4.0</a> 许可协议，转载请注明来自 <a href="http://www.wzhecnu.cn" target="_blank">学习空间</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/GPT/">GPT</a></div><div class="post_share"><div class="social-share" data-image="https://qiniu.wzhecnu.cn/PicBed6/picgo/20240305154701.png" data-sites="weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button button--animated"><i class="fas fa-qrcode"></i> 请作者喝茶</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/02/26/server/zi-dong-jiao-ben/"><img class="prev-cover" src="https://qiniu.wzhecnu.cn/PicBed5/images_for_blogs/zhihu.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">服务器运维 | 自动执行脚本的几种方式</div></div></a></div><div class="next-post pull-right"><a href="/2024/01/29/server/systemctl-xiang-jie/"><img class="next-cover" src="https://qiniu.wzhecnu.cn/PicBed6/picgo/systemctl.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Systemctl 详解：Linux 服务管理工具</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/03/06/gpt/chatgpt/" title="十分钟部署 ChatGPT"><img class="cover" src="https://qiniu.wzhecnu.cn/PicBed3/picgo/20230316131423.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-06</div><div class="title">十分钟部署 ChatGPT</div></div></a></div><div><a href="/2024/01/13/gpt/gpt4-shi-yong-zhi-nan/" title="GPT4 使用指南"><img class="cover" src="https://qiniu.wzhecnu.cn/PicBed6/picgo/20240113131524.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-13</div><div class="title">GPT4 使用指南</div></div></a></div><div><a href="/2023/11/17/gpt/chattool/" title="ChatTool | 一个简单易用的 API 模块"><img class="cover" src="https://qiniu.wzhecnu.cn/PicBed5/images_for_blogs/zhihu.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-17</div><div class="title">ChatTool | 一个简单易用的 API 模块</div></div></a></div><div><a href="/2023/04/15/gpt/gpt-request-forward/" title="API 代理转发 | ChatGPT 应用实战"><img class="cover" src="https://qiniu.wzhecnu.cn/PicBed3/picgo/20230415231826.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-15</div><div class="title">API 代理转发 | ChatGPT 应用实战</div></div></a></div><div><a href="/2023/03/22/gpt/openai-api-call/" title="OpenAI API 调用 | Python 实战"><img class="cover" src="https://qiniu.wzhecnu.cn/PicBed3/picgo/20230322103522.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-22</div><div class="title">OpenAI API 调用 | Python 实战</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://qiniu.wzhecnu.cn/PicBed5/images_for_blogs/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Rex</div><div class="author-info__description">Math + Computer = ?</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">95</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">28</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/RexWzh"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/RexWzh" target="_blank" title="Github"><i class="iconfont icon-github"></i></a><a class="social-icon" href="https://space.bilibili.com/518870168" target="_blank" title="B站"><i class="iconfont icon--bilibili"></i></a><a class="social-icon" href="https://www.zhihu.com/people/wang-zhi-hong-79-21" target="_blank" title="知乎"><i class="iconfont icon-zhihu"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">新功能陆续上线，欢迎交流！干杯！！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%94%A0%E5%94%A0%E9%97%B2%E8%AF%9D"><span class="toc-number">1.</span> <span class="toc-text">唠唠闲话</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E7%89%B9%E6%80%A7"><span class="toc-number">1.1.</span> <span class="toc-text">项目特性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%9A%E5%AE%A2%E5%AE%9A%E4%BD%8D"><span class="toc-number">1.2.</span> <span class="toc-text">博客定位</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2"><span class="toc-number">2.</span> <span class="toc-text">服务部署</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#0-%E5%AE%89%E8%A3%85%E7%8E%AF%E5%A2%83"><span class="toc-number">2.1.</span> <span class="toc-text">0. 安装环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%A8%A1%E5%9E%8B%E7%AE%A1%E7%90%86"><span class="toc-number">2.2.</span> <span class="toc-text">1. 模型管理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.2.1.</span> <span class="toc-text">添加本地模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.2.2.</span> <span class="toc-text">添加嵌入模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#vLLM-%E5%8A%A0%E8%BD%BD%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.2.3.</span> <span class="toc-text">vLLM 加载模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0-API-%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.2.4.</span> <span class="toc-text">添加 API 模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86"><span class="toc-number">2.2.5.</span> <span class="toc-text">模型推理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%90%AF%E5%8A%A8%E6%9C%8D%E5%8A%A1"><span class="toc-number">2.3.</span> <span class="toc-text">2. 启动服务</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD-Embedding-%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.3.1.</span> <span class="toc-text">加载 Embedding 模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">2.3.2.</span> <span class="toc-text">配置环境变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%8D%E5%8A%A1%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.3.3.</span> <span class="toc-text">服务介绍</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94"><span class="toc-number">3.</span> <span class="toc-text">知识问答</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94"><span class="toc-number">3.1.</span> <span class="toc-text">知识库问答</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%97%AE%E7%AD%94"><span class="toc-number">3.2.</span> <span class="toc-text">数据问答</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%80%E5%8F%91%E8%AE%BE%E8%AE%A1"><span class="toc-number">4.</span> <span class="toc-text">开发设计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E7%AB%AF%E9%A1%B5%E9%9D%A2%E9%AD%94%E6%94%B9"><span class="toc-number">5.</span> <span class="toc-text">前端页面魔改</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Rex</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a><br>
<a href="https://beian.miit.gov.cn/"  style="color:#f72b07" target="_blank">粤ICP备2021109780号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.wzhecnu.cn',
      region: ''
    }, null))
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'https://twikoo.wzhecnu.cn',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" data-mobile="true" data-text="欢,迎,来,访,你,好,朋,友" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>